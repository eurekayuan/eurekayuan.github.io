<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Zhuowen Yuan</title> <meta name="author" content="Zhuowen Yuan"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>âš›ï¸</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://eurekayuan.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item"> <a class="nav-link" href="/#News">News</a> </li> <li class="nav-item"> <a class="nav-link" href="/#Publications">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Zhuowen</span> Yuan </h1> <p class="desc"></p> </header> <article> <h2>About</h2> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>Iâ€™m a fourth-year Ph.D. candidate in Computer Science at University of Illinois Urbana-Champaign, advised by Prof. <a href="https://aisecure.github.io/" target="_blank" rel="noopener noreferrer">Bo Li</a> of <a href="https://aisecure.github.io/GROUP/index.html" target="_blank" rel="noopener noreferrer">Secure Learning Lab</a>. My research focuses on the trustworthiness of foundation models and agents.</p> <p>Before that, I received my B.S. in Information Security at Fudan University. My undergraduate advisors are Prof. <a href="https://blazelisheng.github.io/" target="_blank" rel="noopener noreferrer">Sheng Li</a> and Prof. <a href="https://yuanxzhang.github.io/" target="_blank" rel="noopener noreferrer">Yuan Zhang</a>.</p> <p>Besides research, I enjoy playing tennisğŸ¾, guitarğŸ¸ and pianoğŸ¹. My favourite tennis player is Roger Federer.</p> <p>(Last Update: 12/25/2024)</p> </div> <div class="publications" id="Publications"> <h2>Publications</h2> <ol class="bibliography"> <li> <div class="row"> <div id="yuan2024rigor" class="col-sm-12"> <div class="title">RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content</div> <div class="author"> <b>Zhuowen Yuan</b>,Â Zidi Xiong,Â Yi Zeng,Â Ning Yu,Â Ruoxi Jia,Â Dawn Song,Â Bo Li </div> <div class="periodical"> <em>ICML</em> 2024 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="yuan2024shine" class="col-sm-12"> <div class="title">SHINE: Shielding Backdoors in Deep Reinforcement Learning</div> <div class="author"> <b>Zhuowen Yuan</b>,Â Wenbo Guo,Â Jinyuan Jia,Â Bo Li,Â Dawn Song </div> <div class="periodical"> <em>ICML</em> 2024 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="chaudhury2024fair" class="col-sm-12"> <div class="title">Fair Federated Learning via the Proportional Veto Core</div> <div class="author"> Bhaskar Ray Chaudhury,Â Aniket Murhekar,Â  <b>Zhuowen Yuan</b>,Â Bo Li,Â Ruta Mehta,Â Ariel D. Procaccia </div> <div class="periodical"> <em>ICML</em> 2024 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="jia2023fedgame" class="col-sm-12"> <div class="title">FedGame: A Game-Theoretic Defense against Backdoor Attacks in Federated Learning</div> <div class="author"> Jinyuan Jia,Â  <b>Zhuowen Yuan</b>,Â Dinuka Sahabandu,Â Luyao Niu,Â Arezoo Rajabi,Â Bhaskar Ramasubramanian,Â Bo Li,Â Radha Poovendran </div> <div class="periodical"> <em>NeurIPS</em> 2023 </div> <div class="links"> <a class="abstract" style="font-size:14px; color:#0076df" role="button">[Abs]</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/a6678e2be4ce7aef9d2192e03cd586b7-Paper-Conference.pdf" style="font-size:14px" target="_blank" rel="noopener noreferrer">[PDF]</a> <a href="https://github.com/AI-secure/FedGame" style="font-size:14px" target="_blank" rel="noopener noreferrer">[Code]</a> </div> <div class="abstract hidden"> <p>Federated learning (FL) provides a distributed training paradigm where multiple clients can jointly train a global model without sharing their local data. However, recent studies have shown that FL offers an additional surface for backdoor attacks. For instance, an attacker can compromise a subset of clients and thus corrupt the global model to misclassify an input with a backdoor trigger as the adversarial target. Existing defenses for FL against backdoor attacks usually detect and exclude the corrupted information from the compromised clients based on a static attacker model. However, such defenses are inadequate against dynamic attackers who strategically adapt their attack strategies. To bridge this gap, we model the strategic interactions between the defender and dynamic attackers as a minimax game. Based on the analysis of the game, we design an interactive defense mechanism FedGame. We prove that under mild assumptions, the global model trained with FedGame under backdoor attacks is close to that trained without attacks. Empirically, we compare FedGame with multiple state-of-the-art baselines on several benchmark datasets under various attacks. We show that FedGame can effectively defend against strategic attackers and achieves significantly higher robustness than baselines. Our code is available at: https://github.com/AI-secure/FedGame.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="murhekar2023incentives" class="col-sm-12"> <div class="title">Incentives in Federated Learning: Equilibria, Dynamics, and Mechanisms for Welfare Maximization</div> <div class="author"> Aniket Murhekar,Â  <b>Zhuowen Yuan</b>,Â Bhaskar Ray Chaudhury,Â Bo Li,Â Ruta Mehta </div> <div class="periodical"> <em>NeurIPS</em> 2023 </div> <div class="links"> <a class="abstract" style="font-size:14px; color:#0076df" role="button">[Abs]</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/39b77b5e422b4e070e2811b73ea9bcf7-Paper-Conference.pdf" style="font-size:14px" target="_blank" rel="noopener noreferrer">[PDF]</a> </div> <div class="abstract hidden"> <p>Federated learning (FL) has emerged as a powerful scheme to facilitate the collaborative learning of models amongst a set of agents holding their own private data. Although the agents benefit from the global model trained on shared data, by participating in federated learning, they may also incur costs (related to privacy and communication) due to data sharing. In this paper, we model a collaborative FL framework, where every agent attempts to achieve an optimal trade-off between her learning payoff and data sharing cost. We show the existence of Nash equilibrium (NE) under mild assumptions on agentsâ€™ payoff and costs. Furthermore, we show that agents can discover the NE via best response dynamics. However, some of the NE may be bad in terms of overall welfare for the agents, implying little incentive for some fraction of the agents to participate in the learning. To remedy this, we design a budget-balanced mechanism involving payments to the agents, that ensures that any p-mean welfare function of the agentsâ€™ utilities is maximized at NE. In addition, we introduce a FL protocol FedBR-BG that incorporates our budget-balanced mechanism, utilizing best response dynamics. Our empirical validation on MNIST and CIFAR-10 substantiates our theoretical analysis. We show that FedBR-BG outperforms the basic best-response-based protocol without additional incentivization, the standard federated learning protocol FedAvg, as well as a recent baseline MWFed in terms of achieving superior p-mean welfare.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="yuan2022sec" class="col-sm-12"> <div class="title">SecretGen: Privacy Recovery on Pre-trained Models via Distribution Discrimination</div> <div class="author"> <b>Zhuowen Yuan</b>,Â Fan Wu,Â Yunhui Long,Â Chaowei Xiao,Â Bo Li </div> <div class="periodical"> <em>ECCV</em> 2022 </div> <div class="links"> <a class="abstract" style="font-size:14px; color:#0076df" role="button">[Abs]</a> <a href="https://arxiv.org/pdf/2207.12263.pdf" style="font-size:14px" target="_blank" rel="noopener noreferrer">[PDF]</a> <a href="https://github.com/AI-secure/SecretGen" style="font-size:14px" target="_blank" rel="noopener noreferrer">[Code]</a> </div> <div class="abstract hidden"> <p>Transfer learning through the use of pre-trained models has become a growing trend for the machine learning community. Consequently, numerous pre-trained models are released online to facilitate further research. However, it raises extensive concerns on whether these pre-trained models would leak privacy-sensitive information of their training data. Thus, in this work, we aim to answer the following questions: "Can we effectively recover private information from these pre-trained models? What are the sufficient conditions to retrieve such sensitive information?" We first explore different statistical information which can discriminate the private training distribution from other distributions. Based on our observations, we propose a novel private data reconstruction framework, SecretGen, to effectively recover private information. Compared with previous methods which can recover private data with the ground true prediction of the targeted recovery instance, SecretGen does not require such prior knowledge, making it more practical. We conduct extensive experiments on different datasets under diverse scenarios to compare SecretGen with other baselines and provide a systematic benchmark to better understand the impact of different auxiliary information and optimization operations. We show that without prior knowledge about true class prediction, SecretGen is able to recover private data with similar performance compared with the ones that leverage such prior knowledge. If the prior knowledge is given, SecretGen will significantly outperform baseline methods. We also propose several quantitative metrics to further quantify the privacy vulnerability of pre-trained models, which will help the model selection for privacy-sensitive applications. Our code is available at: https://github.com/AI-secure/SecretGen.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="yuan2022ongen" class="col-sm-12"> <div class="title">On Generating Identifiable Virtual Faces</div> <div class="author"> <b>Zhuowen Yuan</b>,Â Zhengxin You,Â Sheng Li,Â Xinpeng Zhang,Â Zhenxin Qian,Â Alex C. Kot </div> <div class="periodical"> <em>ACM MM</em> 2022 </div> <div class="links"> <a class="abstract" style="font-size:14px; color:#0076df" role="button">[Abs]</a> <a href="https://arxiv.org/pdf/2110.07986.pdf" style="font-size:14px" target="_blank" rel="noopener noreferrer">[PDF]</a> </div> <div class="abstract hidden"> <p>Face anonymization with generative models have become increasingly prevalent since they sanitize private information by generating virtual face images, ensuring both privacy and image utility. Such virtual face images are usually not identifiable after the removal or protection of the original identity. In this paper, we formalize and tackle the problem of generating identifiable virtual face images. Our virtual face images are visually different from the original ones for privacy protection. In addition, they are bound with new virtual identities, which can be directly used for face recognition. We propose an Identifiable Virtual Face Generator (IVFG) to generate the virtual face images. The IVFG projects the latent vectors of the original face images into virtual ones according to a user specific key, based on which the virtual face images are generated. To make the virtual face images identifiable, we propose a multi-task learning objective as well as a triplet styled training strategy to learn the IVFG. We evaluate the performance of our virtual face images using different face recognizers on diffident face image datasets, all of which demonstrate the effectiveness of the IVFG for generate identifiable virtual face images.</p> </div> </div> </div> </li> </ol> ("*" denotes equal contribution) </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%72%65%61%6C%7A%68%75%6F%77%65%6E@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope" style="font-size: 0.75em"></i></a> <a href="https://orcid.org/0000-0002-4174-5602" title="ORCID" target="_blank" rel="noopener noreferrer"><i class="ai ai-orcid" style="font-size: 0.75em"></i></a> <a href="https://github.com/eurekayuan" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github" style="font-size: 0.75em"></i></a> <a href="https://twitter.com/ZhuowenYuan" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter" style="font-size: 0.75em"></i></a> </div> <div class="contact-note"> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2026 Zhuowen Yuan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>